@article{Gneiting2007,
    author = {Gneiting, Tilmann and Raftery, Adrian E.},
    doi = {10.1198/016214506000001437},
    journal = {Journal of the American Statistical Association},
    number = {477},
    pages = {359--378},
    title = {{Strictly proper scoring rules, prediction, and estimation}},
    volume = {102},
    year = {2007}
}

@article{Jordan2019,
    author = {Jordan, Alexander and Kr{\"{u}}ger, Fabian and Lerch, Sebastian},
    doi = {10.18637/jss.v090.i12},
    journal = {Journal of Statistical Software},
    number = {12},
    pages = {1--37},
    title = {{Evaluating Probabilistic Forecasts with scoringRules}},
    url = {http://www.jstatsoft.org/v90/i12/},
    volume = {90},
    year = {2019}
}


@article{Smith2015,
    author = {Smith, Leonard A. and Suckling, Emma B. and Thompson, Erica L. and Maynard, Trevor and Du, Hailiang},
    doi = {10.1007/s10584-015-1430-2},
    journal = {Climatic Change},
    number = {1},
    pages = {31--45},
    title = {{Towards improving the framework for probabilistic forecast evaluation}},
    volume = {132},
    year = {2015}
}

@article{Lewis2022,
    author = {Lewis, Abigail S.L. L. and Woelmer, Whitney M. and Wander, Heather L. and Howard, Dexter W. and Smith, John W. and McClure, Ryan P. and Lofton, Mary E. and Hammond, Nicholas W. and Corrigan, Rachel S. and Thomas, R. Quinn and Carey, Cayelan C.},
    doi = {10.1002/eap.2500},
    journal = {Ecological Applications},
    month = {mar},
    number = {2},
    pages = {e02500},
    pmid = {34800082},
    title = {{Increased adoption of best practices in ecological forecasting enables comparisons of forecastability}},
    volume = {32},
    year = {2022}
}

@article{Simonis2021,
    author = {Simonis, Juniper L. and White, Ethan P. and Ernest, S. K.Morgan},
    doi = {10.1002/ecy.3431},
    journal = {Ecology},
    keywords = {continuous analysis,desert pocket mouse,ecological forecasting,end-sample holdout,forecast skill,hierarchical Bayes,prequential,score rule,time series,validation},
    number = {8},
    pages = {1--8},
    title = {{Evaluating probabilistic ecological forecasts}},
    volume = {102},
    year = {2021}
}

@book{Dietze2017,
    author = {Dietze, Michael C.},
    isbn = {9780691160573},
    publisher = {Princeton University Press},
    title = {{Ecological Forecasting}},
    year = {2017}
}

@article{Simonis2021,
    abstract = {Probabilistic near-term forecasting facilitates evaluation of model predictions against observations and is of pressing need in ecology to inform environmental decision-making and effect societal change. Despite this imperative, many ecologists are unfamiliar with the widely used tools for evaluating probabilistic forecasts developed in other fields. We address this gap by reviewing the literature on probabilistic forecast evaluation from diverse fields including climatology, economics, and epidemiology. We present established practices for selecting evaluation data (end-sample hold out), graphical forecast evaluation (times-series plots with uncertainty, probability integral transform plots), quantitative evaluation using scoring rules (log, quadratic, spherical, and ranked probability scores), and comparing scores across models (skill score, Dieboldâ€“Mariano test). We cover common approaches, highlight mathematical concepts to follow, and note decision points to allow application of general principles to specific forecasting endeavors. We illustrate these approaches with an application to a long-term rodent population time series currently used for ecological forecasting and discuss how ecology can continue to learn from and drive the cross-disciplinary field of forecasting science.},
    author = {Simonis, Juniper L. and White, Ethan P. and Ernest, S. K.Morgan},
    doi = {10.1002/ecy.3431},
    issn = {19399170},
    journal = {Ecology},
    pages = {1--8},
    pmid = {34105774},
    title = {{Evaluating probabilistic ecological forecasts}},
    volume = {102},
    year = {2021}
}

@book{Jolliffe2012,
    address = {Oxford},
    author = {Jolliffe, I. T. and Stephenson, David B.},
    edition = {2nd},
    editor = {Jolliffe, Ian T. and Stephenson, David B.},
    publisher = {Wiley Blackwell},
    title = {{Forecast verification: a practitioner's guide in atmospheric science}},
    year = {2012}
}

@article{Pappenberger2015,
    abstract = {The skill of a forecast can be assessed by comparing the relative proximity of both the forecast and a benchmark to the observations. Example benchmarks include climatology or a na{\"{i}}ve forecast. Hydrological ensemble prediction systems (HEPS) are currently transforming the hydrological forecasting environment but in this new field there is little information to guide researchers and operational forecasters on how benchmarks can be best used to evaluate their probabilistic forecasts. In this study, it is identified that the forecast skill calculated can vary depending on the benchmark selected and that the selection of a benchmark for determining forecasting system skill is sensitive to a number of hydrological and system factors. A benchmark intercomparison experiment is then undertaken using the continuous ranked probability score (CRPS), a reference forecasting system and a suite of 23 different methods to derive benchmarks. The benchmarks are assessed within the operational set-up of the European Flood Awareness System (EFAS) to determine those that are 'toughest to beat' and so give the most robust discrimination of forecast skill, particularly for the spatial average fields that EFAS relies upon.Evaluating against an observed discharge proxy the benchmark that has most utility for EFAS and avoids the most na{\"{i}}ve skill across different hydrological situations is found to be meteorological persistency. This benchmark uses the latest meteorological observations of precipitation and temperature to drive the hydrological model. Hydrological long term average benchmarks, which are currently used in EFAS, are very easily beaten by the forecasting system and the use of these produces much na{\"{i}}ve skill. When decomposed into seasons, the advanced meteorological benchmarks, which make use of meteorological observations from the past 20. years at the same calendar date, have the most skill discrimination. They are also good at discriminating skill in low flows and for all catchment sizes. Simpler meteorological benchmarks are particularly useful for high flows. Recommendations for EFAS are to move to routine use of meteorological persistency, an advanced meteorological benchmark and a simple meteorological benchmark in order to provide a robust evaluation of forecast skill. This work provides the first comprehensive evidence on how benchmarks can be used in evaluation of skill in probabilistic hydrological forecasts and which benchmarks are most useful for skill discrimination and avoidance of na{\"{i}}ve skill in a large scale HEPS. It is recommended that all HEPS use the evidence and methodology provided here to evaluate which benchmarks to employ; so forecasters can have trust in their skill evaluation and will have confidence that their forecasts are indeed better.},
    author = {Pappenberger, F. and Ramos, M.H. and Cloke, H.L. and Wetterhall, F. and Alfieri, L. and Bogner, K. and Mueller, A. and Salamon, P.},
    doi = {10.1016/j.jhydrol.2015.01.024},
    journal = {Journal of Hydrology},
    month = {mar},
    pages = {697--713},
    publisher = {Elsevier B.V.},
    title = {{How do I know if my forecasts are better? Using benchmarks in hydrological ensemble prediction}},
    volume = {522},
    year = {2015}
}

@misc{Boettiger2024,
    author = {Boettiger, Carl and Thomas, R. Quinn},
    mendeley-groups = {challenge synthesis},
    title = {{neon4cast: Helper utilities for the EFI NEON Forecast Challenge. R package version 0.1.0}},
    year = {2024}
}

@article{Thomas2023,
    author = {Thomas, R Quinn and Boettiger, Carl and Carey, Cayelan C and Dietze, Michael C and Johnson, Leah R and Kenney, Melissa A and McLachlan, Jason S and Peters, Jody A and Sokol, Eric R and Weltzin, Jake F and Willson, Alyssa and Woelmer, Whitney M},
    doi = {10.1002/fee.2616},
    issn = {1540-9295},
    journal = {Frontiers in Ecology and the Environment},
    month = {apr},
    number = {3},
    pages = {112--113},
    title = {{The NEON Ecological Forecasting Challenge}},
    volume = {21},
    year = {2023}
}

@article{Jacobs2024,
    author = {Jacobs, Bas and Tobi, Hilde and Hengeveld, Geerten M.},
    doi = {10.1016/j.ecolmodel.2023.110562},
    issn = {03043800},
    journal = {Ecological Modelling},
    number = {July 2023},
    pages = {110562},
    title = {{Linking error measures to model questions}},
    volume = {487},
    year = {2024}
}
